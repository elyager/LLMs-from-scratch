{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f896245e-57c4-48fd-854f-9e43f22e10c9",
      "metadata": {
        "id": "f896245e-57c4-48fd-854f-9e43f22e10c9"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785",
      "metadata": {
        "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785"
      },
      "source": [
        "# Appendix A: Introduction to PyTorch (Part 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68",
      "metadata": {
        "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68"
      },
      "source": [
        "## A.1 What is PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
      "metadata": {
        "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
        "outputId": "01a5b3b5-1900-452d-bc9f-b122a96172fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
      "metadata": {
        "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
        "outputId": "9ab2a903-6c6e-44b9-8735-cbc82015dd42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "397ba1ab-3306-4965-8618-1ed5f24fb939",
      "metadata": {
        "id": "397ba1ab-3306-4965-8618-1ed5f24fb939"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/1.webp\" width=\"400px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3c0555-88f6-4515-8c99-aa56b0769d54",
      "metadata": {
        "id": "1e3c0555-88f6-4515-8c99-aa56b0769d54"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/2.webp\" width=\"300px\">\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/3.webp\" width=\"300px\">\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/4.webp\" width=\"500px\">\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/5.webp\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b",
      "metadata": {
        "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b"
      },
      "source": [
        "## A.2 Understanding tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30",
      "metadata": {
        "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/6.webp\" width=\"400px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d7f785-e048-42bc-9182-a556af6bb7f4",
      "metadata": {
        "id": "26d7f785-e048-42bc-9182-a556af6bb7f4"
      },
      "source": [
        "### A.2.1 Scalars, vectors, matrices, and tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a464d6-cec8-4363-87bd-ea4f900baced",
      "metadata": {
        "id": "a3a464d6-cec8-4363-87bd-ea4f900baced"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# create a 0D tensor (scalar) from a Python integer\n",
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "# create a 1D tensor (vector) from a Python list\n",
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "\n",
        "# create a 2D tensor from a nested Python list\n",
        "tensor2d = torch.tensor([[1, 2],\n",
        "                         [3, 4]])\n",
        "\n",
        "# create a 3D tensor from a nested Python list\n",
        "tensor3d_1 = torch.tensor([[[1, 2], [3, 4]],\n",
        "                           [[5, 6], [7, 8]]])\n",
        "\n",
        "# create a 3D tensor from NumPy array\n",
        "ary3d = np.array([[[1, 2], [3, 4]],\n",
        "                  [[5, 6], [7, 8]]])\n",
        "tensor3d_2 = torch.tensor(ary3d)  # Copies NumPy array\n",
        "tensor3d_3 = torch.from_numpy(ary3d)  # Shares memory with NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
      "metadata": {
        "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
        "outputId": "9768b4e1-cba3-4726-abc4-7595d9489a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "ary3d[0, 0, 0] = 999\n",
        "print(tensor3d_2) # remains unchanged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
      "metadata": {
        "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
        "outputId": "e7d70535-e944-4601-8e64-34ae62768b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[999,   2],\n",
            "         [  3,   4]],\n",
            "\n",
            "        [[  5,   6],\n",
            "         [  7,   8]]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor3d_3) # changes because of memory sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63dec48d-2b60-41a2-ac06-fef7e718605a",
      "metadata": {
        "id": "63dec48d-2b60-41a2-ac06-fef7e718605a"
      },
      "source": [
        "### A.2.2 Tensor data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
      "metadata": {
        "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
        "outputId": "1f896a62-441c-4892-9fd4-2be2c0959517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "tensor1d = torch.tensor([1, 2, 3])\n",
        "print(tensor1d.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
      "metadata": {
        "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
        "outputId": "cda2c9e9-645d-43e9-d16c-395a1d9453e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
      "metadata": {
        "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
        "outputId": "5af0eb58-a637-4e4d-d4b5-c843acfe6d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "floatvec = tensor1d.to(torch.float32)\n",
        "print(floatvec.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2020deb5-aa02-4524-b311-c010f4ad27ff",
      "metadata": {
        "id": "2020deb5-aa02-4524-b311-c010f4ad27ff"
      },
      "source": [
        "### A.2.3 Common PyTorch tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
      "metadata": {
        "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
        "outputId": "3c386a6f-6b53-4f11-dc32-68f86a034c33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d = torch.tensor([[1, 2, 3],\n",
        "                         [4, 5, 6]])\n",
        "tensor2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
      "metadata": {
        "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
        "outputId": "8be78bce-c69b-4650-fe28-349468528f1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
      "metadata": {
        "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
        "outputId": "e4eeaae4-0142-41cf-832c-5b30e1a76447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d.reshape(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
      "metadata": {
        "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
        "outputId": "60dd1248-bb4f-4d9b-cff2-9c67224cff70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d.view(3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
      "metadata": {
        "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
        "outputId": "08db0416-cf81-4415-ae86-3f0242ea43ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
      "metadata": {
        "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
        "outputId": "6421ffc0-7be5-43ec-f4c1-0dd827c97d0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d.matmul(tensor2d.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
      "metadata": {
        "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
        "outputId": "9cebd998-6e8b-4b95-9a56-db9013aaaf94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor2d @ tensor2d.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38",
      "metadata": {
        "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38"
      },
      "source": [
        "## A.3 Seeing models as computation graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9",
      "metadata": {
        "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/7.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22af61e9-0443-4705-94d7-24c21add09c7",
      "metadata": {
        "id": "22af61e9-0443-4705-94d7-24c21add09c7",
        "outputId": "20f5edb3-dc6e-45f5-f64a-f03a87a7a0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1]) # input feature\n",
        "w1 = torch.tensor([2.2]) # weight parameter\n",
        "b = torch.tensor([0.0])  # bias unit\n",
        "\n",
        "z = x1 * w1 + b          # net input\n",
        "a = torch.sigmoid(z)     # activation & output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9424f26-2bac-47e7-b834-92ece802247c",
      "metadata": {
        "id": "f9424f26-2bac-47e7-b834-92ece802247c"
      },
      "source": [
        "## A.4 Automatic differentiation made easy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c",
      "metadata": {
        "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/8.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
      "metadata": {
        "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
        "outputId": "a10fe423-067b-4600-fe25-49a8dc4b8d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_L_w1)\n",
        "print(grad_L_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
      "metadata": {
        "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
        "outputId": "e26187a0-0b58-48ea-ab9a-fa581a28b459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ],
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc",
      "metadata": {
        "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc"
      },
      "source": [
        "## A.5 Implementing multilayer neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51",
      "metadata": {
        "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/9.webp\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1",
      "metadata": {
        "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe",
      "metadata": {
        "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(50, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
      "metadata": {
        "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
        "outputId": "9df385d6-d677-4ba1-ae7d-9a4d632e1f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
      "metadata": {
        "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
        "outputId": "347516a2-9561-402a-a940-6ce6393d1149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
      "metadata": {
        "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
        "outputId": "5f701991-f4a8-4943-f632-36d223056ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1182,  0.0606, -0.1292,  ..., -0.1126,  0.0735, -0.0597],\n",
            "        [-0.0249,  0.0154, -0.0476,  ..., -0.1001, -0.1288,  0.1295],\n",
            "        [ 0.0641,  0.0018, -0.0367,  ..., -0.0990, -0.0424, -0.0043],\n",
            "        ...,\n",
            "        [ 0.0618,  0.0867,  0.1361,  ..., -0.0254,  0.0399,  0.1006],\n",
            "        [ 0.0842, -0.0512, -0.0960,  ..., -0.1091,  0.1242, -0.0428],\n",
            "        [ 0.0518, -0.1390, -0.0923,  ..., -0.0954, -0.0668, -0.0037]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(model.layers[0].weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
      "metadata": {
        "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
        "outputId": "dea4ff6a-9c53-4b52-ae75-96085110c0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model.layers[0].weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
      "metadata": {
        "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
        "outputId": "3ebe805c-cf38-475a-e367-63dbb5423dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ],
      "source": [
        "print(model.layers[0].weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
      "metadata": {
        "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
        "outputId": "f3a887b2-f463-4704-8efe-deec22acc21e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "X = torch.rand((1, 50))\n",
        "out = model(X)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
      "metadata": {
        "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
        "outputId": "5074d334-fbf3-4f07-aec4-fb40fa89c7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    out = model(X)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
      "metadata": {
        "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
        "outputId": "b7deb967-e4f2-4861-e510-d758eb4b2b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85",
      "metadata": {
        "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85"
      },
      "source": [
        "## A.6 Setting up efficient data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f98d8fc-5618-47a2-bc72-153818972a24",
      "metadata": {
        "id": "0f98d8fc-5618-47a2-bc72-153818972a24"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/10.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7",
      "metadata": {
        "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88283948-5fca-461a-98a1-788b6be191d5",
      "metadata": {
        "id": "88283948-5fca-461a-98a1-788b6be191d5"
      },
      "outputs": [],
      "source": [
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d",
      "metadata": {
        "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
      "metadata": {
        "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
        "outputId": "0d0f0302-61ff-434b-f953-979896ee626d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf",
      "metadata": {
        "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e",
      "metadata": {
        "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e"
      },
      "outputs": [],
      "source": [
        "test_ds = ToyDataset(X_test, y_test)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d4404c-9884-419f-979c-f659742d86ef",
      "metadata": {
        "id": "99d4404c-9884-419f-979c-f659742d86ef",
        "outputId": "806bbc43-48af-4518-a6cb-7d4da19a3f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ],
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db",
      "metadata": {
        "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
      "metadata": {
        "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
        "outputId": "183eff96-a4ef-48a2-aecf-3f4ee28d8ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
          ]
        }
      ],
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb03ed57-df38-4ee0-a553-0863450df39b",
      "metadata": {
        "id": "eb03ed57-df38-4ee0-a553-0863450df39b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/11.webp\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e",
      "metadata": {
        "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e"
      },
      "source": [
        "## A.7 A typical training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
      "metadata": {
        "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
        "outputId": "1e4348bc-44f6-413b-fc84-0ce0d2775ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # Loss function\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # Optional model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
      "metadata": {
        "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
        "outputId": "0dc76a7f-f88b-45db-b6ae-52949c4652d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
      "metadata": {
        "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
        "outputId": "b5c3ba8f-0a5e-484e-f3ce-89c03cd9d56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)\n",
        "\n",
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
      "metadata": {
        "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
        "outputId": "e7df3e1b-f765-4b69-bcc4-528e92557116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = torch.argmax(outputs, dim=1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
      "metadata": {
        "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
        "outputId": "ba7447de-1d3c-4f21-b77c-6036a0ee152a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions == y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
      "metadata": {
        "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
        "outputId": "721637a4-5c46-40d8-91fb-1795d71b3cba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(predictions == y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4",
      "metadata": {
        "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
      "metadata": {
        "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
        "outputId": "553966d4-b49c-48d2-e705-b81ef95d18dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_accuracy(model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
      "metadata": {
        "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
        "outputId": "1f73831a-fc80-4a4b-8f74-c5b4842c3f9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_accuracy(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d5cd469-3a45-4394-944b-3ce543f41dac",
      "metadata": {
        "id": "4d5cd469-3a45-4394-944b-3ce543f41dac"
      },
      "source": [
        "## A.8 Saving and loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5",
      "metadata": {
        "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
      "metadata": {
        "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
        "outputId": "0f0937e4-36c3-4334-c0cd-d8e05f7bd3e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f891c013-43da-4a05-973d-997be313d2d8",
      "metadata": {
        "id": "f891c013-43da-4a05-973d-997be313d2d8"
      },
      "source": [
        "## A.9 Optimizing training performance with GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e68ae888-cabf-49c9-bad6-ecdce774db57",
      "metadata": {
        "id": "e68ae888-cabf-49c9-bad6-ecdce774db57"
      },
      "source": [
        "### A.9.1 PyTorch computations on GPU devices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141c845f-efe3-4614-b376-b8b7a9a2c887",
      "metadata": {
        "id": "141c845f-efe3-4614-b376-b8b7a9a2c887"
      },
      "source": [
        "See [code-part2.ipynb](code-part2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99811829-b817-42ea-b03e-d35374debcc0",
      "metadata": {
        "id": "99811829-b817-42ea-b03e-d35374debcc0"
      },
      "source": [
        "### A.9.2 Single-GPU training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b21456c-4af7-440f-9e78-37770277b5bc",
      "metadata": {
        "id": "0b21456c-4af7-440f-9e78-37770277b5bc"
      },
      "source": [
        "See [code-part2.ipynb](code-part2.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6eb2d1-a341-4489-b04b-635c26945333",
      "metadata": {
        "id": "db6eb2d1-a341-4489-b04b-635c26945333"
      },
      "source": [
        "### A.9.3 Training with multiple GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d049a81-5fb0-49b5-9d6a-17a9976d8520",
      "metadata": {
        "id": "9d049a81-5fb0-49b5-9d6a-17a9976d8520"
      },
      "source": [
        "See [DDP-script.py](DDP-script.py)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}